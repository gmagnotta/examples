apiVersion: template.openshift.io/v1
kind: Template
labels:
  template: template-infra
message: This is a template to start infra components.
metadata:
  name: template-infra
  annotations:
    description: "infra template"
objects:
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: amqbroker
    labels:
      app: amqbroker
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: amqbroker
    template:
      metadata:
        labels:
          app: amqbroker
      spec:
        containers:
          - name: amqbroker
            image: quay.io/gmagnotta/amqbroker:latest
            ports:
              - containerPort: 61616
                protocol: TCP
              - containerPort: 8080
                protocol: TCP
              - containerPort: 8161
                protocol: TCP
              - containerPort: 8443
                protocol: TCP
            resources:
              requests:
                cpu: "500m"
                memory: "128Mi"
              limits:
                cpu: "1000m"
                memory: "1024Mi"
            imagePullPolicy: Always
        restartPolicy: Always
        terminationGracePeriodSeconds: 30
        dnsPolicy: ClusterFirst
        securityContext: {}
        schedulerName: default-scheduler
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 25%
        maxSurge: 25%
    revisionHistoryLimit: 10
    progressDeadlineSeconds: 600
- apiVersion: v1
  kind: Service
  metadata:
    name: amqbroker
    labels:
      app: amqbroker
  spec:
    ports:
      - name: 61616-tcp
        protocol: TCP
        port: 61616
        targetPort: 61616
      - name: 8080-tcp
        protocol: TCP
        port: 8080
        targetPort: 8080
      - name: 8161-tcp
        protocol: TCP
        port: 8161
        targetPort: 8161
      - name: 8443-tcp
        protocol: TCP
        port: 8443
        targetPort: 8443
    selector:
      app: amqbroker
    type: ClusterIP
    sessionAffinity: None
- apiVersion: route.openshift.io/v1
  kind: Route
  metadata:
    name: amqbroker
    labels:
      app: amqbroker
  spec:
    to:
      kind: Service
      name: amqbroker
      weight: 100
    port:
      targetPort: 8161-tcp
    wildcardPolicy: None
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: datagrid
    labels:
      app: datagrid
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: datagrid
    template:
      metadata:
        labels:
          app: datagrid
      spec:
        containers:
          - name: datagrid
            image: quay.io/gmagnotta/datagrid:latest
            args: ["--cluster-stack=kubernetes", "-Djgroups.dns.query=datagridnodes", "-Dinfinispan.cluster.name=London"]
            ports:
              - containerPort: 11222
                protocol: TCP
              - containerPort: 8080
                protocol: TCP
              - containerPort: 8443
                protocol: TCP
              - containerPort: 7800
                protocol: TCP
            resources:
              requests:
                cpu: "500m"
                memory: "128Mi"
              limits:
                cpu: "1000m"
                memory: "1024Mi"
            imagePullPolicy: IfNotPresent
        restartPolicy: Always
        terminationGracePeriodSeconds: 30
        dnsPolicy: ClusterFirst
        securityContext: {}
        schedulerName: default-scheduler
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 25%
        maxSurge: 25%
    revisionHistoryLimit: 10
    progressDeadlineSeconds: 600
- apiVersion: v1
  kind: Service
  metadata:
    name: datagrid
    labels:
      app: datagrid
  spec:
    ports:
      - name: 11222-tcp
        protocol: TCP
        port: 11222
        targetPort: 11222
      - name: 8080-tcp
        protocol: TCP
        port: 8080
        targetPort: 8080
      - name: 8443-tcp
        protocol: TCP
        port: 8443
        targetPort: 8443
    selector:
      app: datagrid
    type: ClusterIP
    sessionAffinity: None
- apiVersion: v1
  kind: Service
  metadata:
    name: datagridnodes
    labels:
      app: datagridnodes
  spec:
    publishNotReadyAddresses: true
    clusterIP: None
    ports:
      - name: 7800-tcp
        protocol: TCP
        port: 7800
        targetPort: 7800
    selector:
      app: datagrid
- apiVersion: route.openshift.io/v1
  kind: Route
  metadata:
    name: datagrid
    labels:
      app: datagrid
  spec:
    to:
      kind: Service
      name: datagrid
      weight: 100
    port:
      targetPort: 11222-tcp
    wildcardPolicy: None
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: amqstreams
    labels:
      app: amqstreams
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: amqstreams
    template:
      metadata:
        labels:
          app: amqstreams
      spec:
        containers:
          - name: zookeeper
            image: quay.io/gmagnotta/amqstreams
            command: ["/opt/kafka/bin/zookeeper-server-start.sh" ]
            args: ["/opt/kafka/config/zookeeper.properties"]
          - name: kafka
            image: quay.io/gmagnotta/amqstreams
            command: ["/opt/kafka/bin/kafka-server-start.sh"]
            args: ["/opt/kafka/config/server.properties"]
            ports:
              - containerPort: 9092
                protocol: TCP
            resources:
              requests:
                cpu: "500m"
                memory: "128Mi"
              limits:
                cpu: "1000m"
                memory: "1024Mi"
            imagePullPolicy: IfNotPresent
        restartPolicy: Always
        terminationGracePeriodSeconds: 30
        dnsPolicy: ClusterFirst
        securityContext: {}
        schedulerName: default-scheduler
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 25%
        maxSurge: 25%
    revisionHistoryLimit: 10
    progressDeadlineSeconds: 600
- apiVersion: v1
  kind: Service
  metadata:
    name: amqstreams
    labels:
      app: amqstreams
  spec:
    ports:
      - name: 9092-tcp
        protocol: TCP
        port: 9092
        targetPort: 9092
    selector:
      app: amqstreams
    type: ClusterIP
    sessionAffinity: None
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: jaeger
    labels:
      app: jaeger
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: jaeger
    template:
      metadata:
        labels:
          app: jaeger
      spec:
        containers:
          - name: jaeger
            image: quay.io/jaegertracing/all-in-one:1.21.0
            ports:
              - containerPort: 5775
                protocol: UDP
              - containerPort: 6831
                protocol: UDP
              - containerPort: 6832
                protocol: UDP
              - containerPort: 5778
                protocol: TCP
              - containerPort: 16686
                protocol: TCP
              - containerPort: 14268
                protocol: TCP
            resources:
              requests:
                cpu: "500m"
                memory: "128Mi"
              limits:
                cpu: "1000m"
                memory: "1024Mi"
            imagePullPolicy: IfNotPresent
        restartPolicy: Always
        terminationGracePeriodSeconds: 30
        dnsPolicy: ClusterFirst
        securityContext: {}
        schedulerName: default-scheduler
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 25%
        maxSurge: 25%
    revisionHistoryLimit: 10
    progressDeadlineSeconds: 600
- apiVersion: v1
  kind: Service
  metadata:
    name: jaeger
    labels:
      app: jaeger
  spec:
    ports:
      - name: 5775-udp
        protocol: UDP
        port: 5775
        targetPort: 5775
      - name: 6831-udp
        protocol: UDP
        port: 6831
        targetPort: 6831
      - name: 6832-udp
        protocol: UDP
        port: 6832
        targetPort: 6832
      - name: 5778-tcp
        protocol: TCP
        port: 5778
        targetPort: 5778
      - name: 16686-tcp
        protocol: TCP
        port: 16686
        targetPort: 16686
      - name: 14268-tcp
        protocol: TCP
        port: 14268
        targetPort: 14268
    selector:
      app: jaeger
    type: ClusterIP
    sessionAffinity: None
- apiVersion: route.openshift.io/v1
  kind: Route
  metadata:
    name: jaeger
    labels:
      app: jaeger
  spec:
    to:
      kind: Service
      name: jaeger
      weight: 100
    port:
      targetPort: 16686-tcp
    wildcardPolicy: None
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: prometheus
    labels:
      app: prometheus
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: prometheus
    template:
      metadata:
        labels:
          app: prometheus
      spec:
        containers:
          - name: prometheus
            image: quay.io/gmagnotta/prometheus
            args: ["--config.file=/opt/prometheus/config/prometheus.yml"]
            ports:
              - containerPort: 9090
                protocol: TCP
            resources:
              requests:
                cpu: "500m"
                memory: "128Mi"
              limits:
                cpu: "1000m"
                memory: "1024Mi"
            imagePullPolicy: IfNotPresent
            volumeMounts:
              - name: config-volume
                mountPath: /opt/prometheus/config
        volumes:
          - name: config-volume
            configMap:
              name: prometheus
              items:
              - key: prometheus.yaml
                path: prometheus.yml
        restartPolicy: Always
        terminationGracePeriodSeconds: 30
        dnsPolicy: ClusterFirst
        securityContext: {}
        schedulerName: default-scheduler
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 25%
        maxSurge: 25%
    revisionHistoryLimit: 10
    progressDeadlineSeconds: 600
- apiVersion: v1
  kind: Service
  metadata:
    name: prometheus
    labels:
      app: prometheus
  spec:
    ports:
      - name: 9090-tcp
        protocol: TCP
        port: 9090
        targetPort: 9090
    selector:
      app: prometheus
    type: ClusterIP
    sessionAffinity: None
- apiVersion: route.openshift.io/v1
  kind: Route
  metadata:
    name: prometheus
    labels:
      app: prometheus
  spec:
    to:
      kind: Service
      name: prometheus
      weight: 100
    port:
      targetPort: 9090-tcp
    wildcardPolicy: None
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: prometheus
  data:
    prometheus.yaml: |-
      # my global config
      global:
        scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
        # evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
        # scrape_timeout is set to the global default (10s).
        external_labels:
          monitor: 'codelab-monitor'

      # Alertmanager configuration
      alerting:
        alertmanagers:
          - static_configs:
              - targets:
                # - alertmanager:9093

      # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
      rule_files:
        # - "first_rules.yml"
        # - "second_rules.yml"

      # A scrape configuration containing exactly one endpoint to scrape:
      # Here it's Prometheus itself.
      scrape_configs:
        # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
        - job_name: "kubernetes-service-endpoints"

          kubernetes_sd_configs:
            - role: endpoints

          tls_config:
            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            insecure_skip_verify: true
          authorization:
            credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token

          relabel_configs:

            # Relabel to scrape only endpoints that have
            # "prometheus.io/scrape = true" annotation.
            - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
              action: keep
              regex: true
            # Relabel to scrape only single, desired port for the service based
            # on endpoints "prometheus.io/scrape_port = <port>" annotation.
            - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_scrape_port]
              action: replace
              regex: ([^:]+)(?::\d+)?;(\d+)
              replacement: $1:$2
              target_label: __address__
        - job_name: "prometheus"

          static_configs:
            - targets: ["localhost:8080"]
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: keycloak
    labels:
      app: keycloak
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: keycloak
    template:
      metadata:
        labels:
          app: keycloak
      spec:
        containers:
          - name: keycloak
            image: quay.io/keycloak/keycloak
            env:
              - name: KEYCLOAK_USER
                valueFrom:
                  configMapKeyRef:
                    name: keycloak
                    key: KEYCLOAK_USER
              - name: KEYCLOAK_PASSWORD
                valueFrom:
                  configMapKeyRef:
                    name: keycloak
                    key: KEYCLOAK_PASSWORD
              - name: DB_VENDOR
                valueFrom:
                  configMapKeyRef:
                    name: keycloak
                    key: DB_VENDOR
              - name: DB_ADDR
                valueFrom:
                  configMapKeyRef:
                    name: keycloak
                    key: DB_ADDR
              - name: DB_PORT
                valueFrom:
                  configMapKeyRef:
                    name: keycloak
                    key: DB_PORT
              - name: DB_DATABASE
                valueFrom:
                  configMapKeyRef:
                    name: keycloak
                    key: DB_DATABASE
              - name: DB_USER
                valueFrom:
                  configMapKeyRef:
                    name: keycloak
                    key: DB_USER
              - name: DB_PASSWORD
                valueFrom:
                  configMapKeyRef:
                    name: keycloak
                    key: DB_PASSWORD
              - name: JGROUPS_DISCOVERY_PROTOCOL
                value: "dns.DNS_PING"
              - name: JGROUPS_DISCOVERY_PROPERTIES
                value: "dns_query=keycloak-ping"
            ports:
              - containerPort: 8080
                protocol: TCP
              - containerPort: 7600
                protocol: TCP
            resources:
              requests:
                cpu: "500m"
                memory: "128Mi"
              limits:
                cpu: "1000m"
                memory: "1024Mi"
            imagePullPolicy: IfNotPresent
        restartPolicy: Always
        terminationGracePeriodSeconds: 30
        dnsPolicy: ClusterFirst
        securityContext: {}
        schedulerName: default-scheduler
    strategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: 25%
        maxSurge: 25%
    revisionHistoryLimit: 10
    progressDeadlineSeconds: 600
- apiVersion: v1
  kind: Service
  metadata:
    name: keycloak
    labels:
      app: keycloak
  spec:
    ports:
      - name: 8080-tcp
        protocol: TCP
        port: 8080
        targetPort: 8080
    selector:
      app: keycloak
    type: ClusterIP
    sessionAffinity: None
- apiVersion: v1
  kind: Service
  metadata:
    name: keycloak-ping
    labels:
      app: keycloak
    annotations:
      service.alpha.kubernetes.io/tolerate-unready-endpoints: true
      description: "The JGroups ping port for clustering"
  spec:
    publishNotReadyAddresses: true
    clusterIP: None
    ports:
      - name: 7600-tcp
        protocol: TCP
        port: 7600
        targetPort: 7600
    selector:
      app: keycloak
- apiVersion: route.openshift.io/v1
  kind: Route
  metadata:
    name: keycloak
    labels:
      app: keycloak
  spec:
    to:
      kind: Service
      name: keycloak
      weight: 100
    port:
      targetPort: 8080-tcp
    wildcardPolicy: None
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: keycloak
  data:
    KEYCLOAK_USER: 'admin'
    KEYCLOAK_PASSWORD: '4dmin'
    DB_VENDOR: 'postgres'
    DB_ADDR: 'postgresql'
    DB_PORT: '5432'
    DB_DATABASE: 'keycloak'
    DB_USER: 'keycloak'
    DB_PASSWORD: 'keycloak'
parameters:
